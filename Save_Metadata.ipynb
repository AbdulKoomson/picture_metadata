{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0887fb1c-8776-4a3b-a1f1-eb20fa6beaf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install the ODBC driver\n",
    "%pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ebb258-f54c-4c20-ac01-03f2d6230886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc9ac682-6d55-46cb-b625-1d50cf2344e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "# Import Microsoft GPG key\n",
    "curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
    "\n",
    "# Add Microsoft package repository\n",
    "curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
    "\n",
    "# Update package lists\n",
    "apt-get update\n",
    "\n",
    "# Install ODBC Driver 18 for SQL Server\n",
    "ACCEPT_EULA=Y apt-get install -y msodbcsql18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c50f4d-b5cc-4641-a70f-873f373b7c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, BooleanType\n",
    "import logging\n",
    "import pyodbc\n",
    "import ast\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "log_dir = \"/dbfs/tmp/logs\"  # Separate directory for logs\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_dir, f\"myapp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get metadata and image path from Databricks widgets\n",
    "# Create widgets for metadata and image data path\n",
    "dbutils.widgets.text(\"metadata\", \"\")\n",
    "dbutils.widgets.text(\"imageDataPath\", \"\")\n",
    "\n",
    "# Retrieve widget values\n",
    "metadata_str = dbutils.widgets.get(\"metadata\")\n",
    "image_data_path = dbutils.widgets.get(\"imageDataPath\")\n",
    "\n",
    "# Log retrieved values\n",
    "logger.info(f\"Received metadata: {metadata_str}\")\n",
    "logger.info(f\"Received image data path: {image_data_path}\")\n",
    "\n",
    "\n",
    "# Parse the metadata string into a dictionary\n",
    "metadata = ast.literal_eval(metadata_str)\n",
    "\n",
    "# Azure SQL Database connection settings\n",
    "server   = dbutils.secrets.get(scope=\"dear-keyvault-scope\", key=\"dearsql-server\")\n",
    "database = dbutils.secrets.get(scope=\"dear-keyvault-scope\", key=\"dearsql-database\")\n",
    "username = dbutils.secrets.get(scope=\"dear-keyvault-scope\", key=\"dearsql-username\")\n",
    "password = dbutils.secrets.get(scope=\"dear-keyvault-scope\", key=\"dearsql-password\")\n",
    "\n",
    "\n",
    "# Establish ODBC connection\n",
    "try:\n",
    "    conn = pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 18 for SQL Server};\"\n",
    "        \"Server=tcp:dearsqldbserver.database.windows.net,1433;\"\n",
    "        \"Database=dearsqldb;\"\n",
    "        \"Uid=dearsqldbadmin;\"\n",
    "        f\"Pwd={password};\"\n",
    "        \"Encrypt=yes;\"\n",
    "        \"TrustServerCertificate=no;\"\n",
    "        \"Connection Timeout=260;\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    logger.info(\"Connected to Azure SQL Database successfully\")\n",
    "\n",
    "    # Check and add new columns dynamically\n",
    "    for key in metadata.keys():\n",
    "        cursor.execute(f\"\"\"\n",
    "            IF NOT EXISTS (\n",
    "                SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                WHERE TABLE_NAME = 'ImageMetadata' AND COLUMN_NAME = ?\n",
    "            )\n",
    "            BEGIN\n",
    "                ALTER TABLE ImageMetadata ADD [{key}] NVARCHAR(MAX);\n",
    "            END;\n",
    "        \"\"\", key)\n",
    "        logger.info(f\"Checked/added column: {key}\")\n",
    "    \n",
    "    # Prepare INSERT query dynamically based on metadata keys\n",
    "    columns = [\"ImageDataPath\", \"Inserted_Time\"] + [f\"[{key}]\" for key in metadata.keys()]\n",
    "    placeholders = [\"?\", \"?\"] + [\"?\" for _ in metadata.keys()]\n",
    "    insert_query = f\"INSERT INTO ImageMetadata ({', '.join(columns)}) VALUES ({', '.join(placeholders)})\"\n",
    "\n",
    "    # Insert data\n",
    "    Inserted_Time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    values = [Image_data_path, Inserted_Time] + [str(metadata[key]) if metadata[key] is not None else None for key in metadata.keys()] \n",
    "    cursor.execute(insert_query, values)\n",
    "    logger.info(f\"Inserted data into ImageMetadata with imageDataPath: {Image_data_path} and inserted_at: {Inserted_Time}\")\n",
    "\n",
    "    # Commit changes\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    logger.info(\"Data inserted into Azure SQL Database successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error inserting data into Azure SQL Database: {e}\")\n",
    "    raise\n",
    "\n",
    "# Exit notebook and return metadata\n",
    "dbutils.notebook.exit(metadata)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Save_Metadata",
   "widgets": {
    "metadata": {
     "currentValue": "",
     "nuid": "329d6007-a1f7-4c95-824e-77a290d8dcb4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "metadata",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "metadata",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
